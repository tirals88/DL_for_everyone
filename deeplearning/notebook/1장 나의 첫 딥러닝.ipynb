{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mSvnn-ZWd9ef",
        "UhcQBmxwO5Vm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirals88/DL_for_everyone/blob/main/deeplearning/notebook/1%EC%9E%A5%20%EB%82%98%EC%9D%98%20%EC%B2%AB%20%EB%94%A5%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'모두의 딥러닝' 책 스터디 내용을 jupyter notebook으로 정리하여 올립니다.\n",
        "\n",
        "Github 주소 : 'https://github.com/gilbutITbook/080228'\n",
        "\n",
        "**모두의 딥러닝**\n",
        "\n"
      ],
      "metadata": {
        "id": "WdeE-kzODzDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01 장 나의 첫 딥러닝"
      ],
      "metadata": {
        "id": "mSvnn-ZWd9ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 폐암 수술 환자의 생존율 예측하기 실습 / 예제 코드\n",
        "\n",
        "# 딥러닝 구동을 위한 케라스 함수 호출\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "#필요한 라이브러리 불러오기\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
        "\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "# 준비된 수술 환자 데이터 불러오기\n",
        "Data_set = np.loadtxt(\"https://raw.githubusercontent.com/tirals88/DL_for_everyone/main/deeplearning/dataset/ThoraricSurgery.csv\", delimiter=\",\")\n",
        "\n",
        "#환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
        "X = Data_set[:, 0:17]\n",
        "Y = Data_set[:, 17]\n",
        "\n",
        "#딥러닝 구조를 결정(모델 설정 / 실행)\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#실행\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100, batch_size = 10)"
      ],
      "metadata": {
        "id": "mty06N0Us27w",
        "outputId": "63a7de1b-2677-4cb3-f3e5-f5a80809288d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 1s 2ms/step - loss: 0.1485 - accuracy: 0.8426\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.8511\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.8489\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.8511\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.8468\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.8489\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.8447\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.8447\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.8511\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.8489\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.8511\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 0.8489\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.8511\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.8511\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.8532\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.8426\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.8511\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.8511\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.8489\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.8489\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.8468\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.8532\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.8511\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.8489\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.8511\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.8511\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.8489\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.8511\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.8511\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.8489\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.8532\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.8511\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.8511\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.8489\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.8468\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.8511\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.8511\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.8532\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.8511\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.8426\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.8511\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.8489\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.8532\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.8489\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.8532\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.8511\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.8511\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.8511\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.8553\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.8532\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.8511\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.8489\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.8489\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.8532\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.8511\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.8468\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.8489\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.8553\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.8596\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.8532\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.8489\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.8553\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.8553\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.8553\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.8511\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.8553\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.8489\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.8574\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.8447\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.8404\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.8532\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.8574\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.8511\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.8553\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.8447\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.8489\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.8532\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.8553\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.8553\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.8617\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.8532\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.8383\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.8426\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.8574\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.8489\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.8532\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.8489\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.8596\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.8638\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.8596\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.8532\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.8574\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.8638\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.8532\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.8532\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.8447\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.8596\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.8638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4cef14be80>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "```\n",
        "\n",
        "Sequential 모델은 레이어를 선형으로 연결하여 구성한다.\n",
        "\n",
        "(출처 : \"https://keras.io/ko/getting-started/sequential-model-guide/\")\n",
        "\n",
        "그리고 Dense 의 주요 인자들은 다음과 같다.\n",
        "\n",
        "- 첫번째 인자(units): 출력 뉴런의 수를 설정합니다.\n",
        "- input_dim : 입력 뉴련의 수를 설정합니다.\n",
        "- kernel_initializer : 가중치를 초기화하는 방법을 설정합니다.\n",
        "-- uniform : 균일 분포\n",
        "-- normal : 가우시안 분포\n",
        "- activation : 활성화함수를 설정합니다.\n",
        "-- linear : 디폴트 값으로 입력값과 가중치로 계산된 결과 값이 그대로 출력으로 나옵니다\n",
        "-- sigmoid : 시그모이드 함수로 이진분류에서 출력층에 주로 쓰입니다\n",
        "-- softmax : 소프드맥스 함수로 다중클래스 분류문제에서 출력층에 주로 쓰입니다.\n",
        "-- relu: Rectified Linear Unit 함수로 은닉층에서 주로 쓰입니다.\n",
        "(출처 : \"https://sevillabk.github.io/Dense/\")\n",
        "\n",
        "이 예제에서는 환자의 기록 데이터인 X 를 17개의 뉴런으로 입력받아서, 30개의 뉴런으로 출력하는 'ReLU' 층과, \n",
        "\n",
        "이진분류로 출력하는 'Sigmoid' 층으로 총 두개의 층이 있다.\n",
        "\n",
        "이 부분에 대해서는 이전에 공부했던 'Deeplearning for Scratch' notebook 에 설명이 있다. ('https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/1%EA%B6%8C_2%EC%9E%A5_%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0_%2B_3%EC%9E%A5_%EC%8B%A0%EA%B2%BD%EB%A7%9D(3%EC%B8%B5_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%EA%B9%8C%EC%A7%80).ipynb')\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "optimizer 의 'Adam'은 'AdaGrad' 와 'Momentum' 의 장점을 더한 매개변수 갱신법이다.\n",
        "\n",
        "AdaGrad는 매개변수의 원소마다 적응적으로 갱신 정도를 조정하고 모멘텀 모델은 공이 그릇 바닥을 구르는 듯한 움직임을 보인다.\n",
        "\n",
        "이 부분에 대한 설명 또한 이전 notebook 에 있다. ('https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/1%EA%B6%8C_6%EC%9E%A5_(1)_%ED%95%99%EC%8A%B5_%EA%B4%80%EB%A0%A8_%EA%B8%B0%EC%88%A0%EB%93%A4.ipynb')\n"
      ],
      "metadata": {
        "id": "9r0M6UHLgu1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 분석\n",
        "\n"
      ],
      "metadata": {
        "id": "oHISo6VYibkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 고찰\n",
        "\n",
        "predict() 메서드의 출력 결과가 test_target의 출력과 동일하게 array()로 감싸 있는 것을 확인할 수 있다. 넘파이 배열을 의미하며 predict()가 반환하는 값은 파이썬 리스트가 아닌, 넘파이 배열이다.\n",
        "\n",
        "**이 절에서는 넘파이의 shuffle() 함수를 사용해 배열의 인덱스를 섞어 골고루 훈련과 테스트 세트로 나누어 학습을 하였다.**"
      ],
      "metadata": {
        "id": "ywx7fDpHogsx"
      }
    }
  ]
}