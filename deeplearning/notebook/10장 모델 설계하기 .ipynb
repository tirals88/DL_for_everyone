{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mSvnn-ZWd9ef",
        "UhcQBmxwO5Vm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirals88/DL_for_everyone/blob/main/deeplearning/notebook/10%EC%9E%A5%20%EB%AA%A8%EB%8D%B8%20%EC%84%A4%EA%B3%84%ED%95%98%EA%B8%B0%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'모두의 딥러닝' 책 스터디 내용을 jupyter notebook으로 정리하여 올립니다.\n",
        "\n",
        "Github 주소 : 'https://github.com/gilbutITbook/080228'\n",
        "\n",
        "**모두의 딥러닝**"
      ],
      "metadata": {
        "id": "WdeE-kzODzDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 장 모델 설계하기기\n",
        "\n",
        "01장에서 **폐암 수술 환자의 생존율 예측하기** 예제 코드를 잠시 보았다.\n",
        "\n",
        "먼저 해당 코드를 다시 보면 다음과 같다.\n"
      ],
      "metadata": {
        "id": "mSvnn-ZWd9ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 폐암 수술 환자의 생존율 예측하기 실습 / 예제 코드\n",
        "\n",
        "# 딥러닝 구동을 위한 케라스 함수 호출\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "#필요한 라이브러리 불러오기\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
        "\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "# 준비된 수술 환자 데이터 불러오기\n",
        "Data_set = np.loadtxt(\"https://raw.githubusercontent.com/tirals88/DL_for_everyone/main/deeplearning/dataset/ThoraricSurgery.csv\", delimiter=\",\")\n",
        "\n",
        "#환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
        "X = Data_set[:, 0:17]\n",
        "Y = Data_set[:, 17]\n",
        "\n",
        "#딥러닝 구조를 결정(모델 설정 / 실행)\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#실행\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100, batch_size = 10)"
      ],
      "metadata": {
        "id": "eKROL3263FGD",
        "outputId": "eaccc3ff-bf53-448f-a1fe-98addc47f4ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 2s 5ms/step - loss: 0.1674 - accuracy: 0.8170\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.1471 - accuracy: 0.8511\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.1467 - accuracy: 0.8468\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.8511\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.1438 - accuracy: 0.8489\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.8489\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.8511\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.8511\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.1440 - accuracy: 0.8511\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.8532\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.8468\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.1449 - accuracy: 0.8511\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 0.1424 - accuracy: 0.8489\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.8511\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.8468\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.1416 - accuracy: 0.8489\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.1421 - accuracy: 0.8532\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.1407 - accuracy: 0.8532\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 0.1389 - accuracy: 0.8511\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.1410 - accuracy: 0.8532\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.1432 - accuracy: 0.8489\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.8532\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 0.1392 - accuracy: 0.8532\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 0.1371 - accuracy: 0.8511\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.1396 - accuracy: 0.8468\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.1404 - accuracy: 0.8532\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.1372 - accuracy: 0.8511\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.8511\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.8511\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.8447\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1353 - accuracy: 0.8574\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1366 - accuracy: 0.8553\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.8574\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.8511\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.8511\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.8511\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.8553\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.8489\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.8511\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.8532\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.8489\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.8511\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.8532\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.8532\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.8553\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 0.8553\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.8489\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.8553\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.8489\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.8553\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.8532\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.8532\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.8511\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.8532\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.8489\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.8553\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.8489\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.8532\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.8532\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.8426\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.8489\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.8511\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.8574\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.8447\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.8532\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.8617\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.8468\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.8532\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.8468\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.8617\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.8574\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.8596\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.8638\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.8574\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.8532\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.8574\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.8553\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.8574\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.8553\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.8574\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.8660\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.8553\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.8511\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.8511\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.8617\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.8660\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.8596\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.8574\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.8596\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.8681\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.8596\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.8553\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.8596\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.8660\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.8574\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.8404\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.8596\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.8617\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb346f44f40>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 위 코드는 **model**이라는 함수를 선언하며 시작이 된다.\n",
        ">> **model.compile()** 부분은 위에서 정해진 모델을 컴퓨터가 알아들을 수 있게끔 컴파일 하는 부분이다.\n",
        ">>>**model.fit()**으로 시작하는 부분은 모델을 실제로 수행하는 부분이다.\n",
        "\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=17, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "```\n",
        "딥러닝이란 퍼센트론 위에 숨겨진 퍼셉트론 층을 차곡차곡 추가하는 형태임을 배웠다.\n",
        "\n",
        "이 층들이 케라스에서는 **Sequential()** 함수를 통해 쉽게 구현된다.\n",
        "\n",
        "위와 같이 Sequential() 함수를 선언한 후, add() 를 통해 새로운 층을 만들 수 있다.\n",
        "\n",
        "따라서 위 모델은 두 개의 층을 가진 모델이며, 마지막 층은 결과를 출력하는 '출력층'이 된다.</br>이 때 나머지층은 모두 '은닉층'이 된다.\n",
        "\n",
        "그리고 각각의 층은 **Dense**라는 함수를 통해 구체적으로 그 구조가 결정이 된다.\n",
        "\n",
        "```\n",
        "Dense(30, input_dim=17, activation='relu')\n",
        "```\n",
        "Dense()함수를 통해 이 층에 몇 개의 노드를 만들 것인지를 숫자로 써준다.</br>이어서 입력 데이터를 몇 개 가져올 것인지 **input_dim**을 통해서 정해준다.\n",
        "</br>이제 은닉층의 각 노드는 17개의 입력 값에서 임의의 가중치를 가지고(편향값도 더해졌을 수도 있음) 각 노드로 전송되어 활성화 함수를 만난다.</br>이 때 어떤 활성화 함수를 사용할 것인지를 **activation** 부분에 정해준다.\n",
        "\n",
        "```\n",
        "Dense(1, activation='sigmoid')\n",
        "\n",
        "```\n",
        "마지막 층은 출력층으로 1개의 노드를 필요로 하며 시그모이드 함수를 사용하였다.\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100, batch_size = 10)\n",
        "```\n",
        "\n",
        "모델 컴파일 부분은 오차함수를 **평균 제곱 오차 함수 mean squared error**를 사용하며 최적화 방식은 **adam**으로 지정하였다.\n",
        "\n",
        "다음으로 **metrics()** 부분은 모델이 컴파일될 때 모델 수행 결과를 나타내게끔 설정하는 부분이다.\n",
        "\n",
        "척도(metrics)의 개념으로는 정확도/정밀도/재현율 등이 있으며 케라스 척도의 종류는 [다음](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)에서 볼 수 있다.\n"
      ],
      "metadata": {
        "id": "crP4NUqmUTe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 교차 엔트로피 Cross entropy\n",
        "\n",
        "교차 엔트로피는 분류 문제에서 자주 사용되며 특별히 예측 값이 참과 거짓 둘 중 하나인 형식일 때는 **binary_crossentropy** (이항 교체 엔트로피)를 쓴다. 위의 예시가 좋은 예이다.\n",
        "\n",
        "위 코드에 적용하고 싶은 경우\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "이항 교차 엔트로피 적용\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "```\n",
        "아래와 같이 바꾸어주면 된다."
      ],
      "metadata": {
        "id": "GZZXs6qajawa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#실행\n",
        "model2.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "model2.fit(X, Y, epochs=100, batch_size = 10)"
      ],
      "metadata": {
        "id": "nBW2GcZumTLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tmvA5Qpcma2v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}