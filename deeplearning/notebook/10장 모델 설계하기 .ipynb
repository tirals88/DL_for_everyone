{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mSvnn-ZWd9ef",
        "UhcQBmxwO5Vm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirals88/DL_for_everyone/blob/main/deeplearning/notebook/10%EC%9E%A5%20%EB%AA%A8%EB%8D%B8%20%EC%84%A4%EA%B3%84%ED%95%98%EA%B8%B0%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'모두의 딥러닝' 책 스터디 내용을 jupyter notebook으로 정리하여 올립니다.\n",
        "\n",
        "Github 주소 : 'https://github.com/gilbutITbook/080228'\n",
        "\n",
        "**모두의 딥러닝**"
      ],
      "metadata": {
        "id": "WdeE-kzODzDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 장 모델 설계하기기\n",
        "\n",
        "01장에서 **폐암 수술 환자의 생존율 예측하기** 예제 코드를 잠시 보았다.\n",
        "\n",
        "먼저 해당 코드를 다시 보면 다음과 같다.\n"
      ],
      "metadata": {
        "id": "mSvnn-ZWd9ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 폐암 수술 환자의 생존율 예측하기 실습 / 예제 코드\n",
        "\n",
        "# 딥러닝 구동을 위한 케라스 함수 호출\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "#필요한 라이브러리 불러오기\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
        "\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "# 준비된 수술 환자 데이터 불러오기\n",
        "Data_set = np.loadtxt(\"https://raw.githubusercontent.com/tirals88/DL_for_everyone/main/deeplearning/dataset/ThoraricSurgery.csv\", delimiter=\",\")\n",
        "\n",
        "#환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
        "X = Data_set[:, 0:17]\n",
        "Y = Data_set[:, 17]\n",
        "\n",
        "#딥러닝 구조를 결정(모델 설정 / 실행)\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#실행\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100, batch_size = 10)"
      ],
      "metadata": {
        "id": "eKROL3263FGD",
        "outputId": "9e6c5ab8-423f-4049-b549-fabf0a9c0377",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 1s 2ms/step - loss: 0.1626 - accuracy: 0.8277\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.8511\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.8511\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.8511\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.8426\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.8511\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.8468\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.8511\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.8532\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.8447\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.8511\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.8511\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.8468\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.8511\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.8511\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.8511\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.8511\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.8511\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.8511\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.8489\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.8532\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.8511\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.8511\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.8511\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.8511\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.8489\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.8532\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.8532\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.8489\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.8489\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.8511\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.8489\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.8532\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.8532\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.8532\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.8489\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.8532\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.8489\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.8511\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.8489\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.8532\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.8511\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.8532\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.8489\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.8532\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.8532\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.8532\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.8511\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.8511\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.8511\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.8489\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.8511\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.8532\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.8532\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.8532\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.8511\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.8532\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.8511\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.8511\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.8532\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.8532\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.8489\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.8532\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.8511\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.8511\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.8532\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.8532\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.8511\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.8532\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.8532\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.8532\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.8532\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.8532\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.8532\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.8532\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.8574\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.8532\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.8489\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.8532\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.8532\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.8553\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.8532\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.8532\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.8511\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.8532\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.8553\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.8553\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.8511\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.8532\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.8532\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.8553\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.8553\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.8532\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.8553\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.8532\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.8553\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.8596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc157292cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 위 코드는 **model**이라는 함수를 선언하며 시작이 된다.\n",
        ">> **model.compile()** 부분은 위에서 정해진 모델을 컴퓨터가 알아들을 수 있게끔 컴파일 하는 부분이다.\n",
        ">>>**model.fit()**으로 시작하는 부분은 모델을 실제로 수행하는 부분이다.\n",
        "\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=17, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "```\n",
        "딥러닝이란 퍼센트론 위에 숨겨진 퍼셉트론 층을 차곡차곡 추가하는 형태임을 배웠다.\n",
        "\n",
        "이 층들이 케라스에서는 **Sequential()** 함수를 통해 쉽게 구현된다.\n",
        "\n",
        "위와 같이 Sequential() 함수를 선언한 후, add() 를 통해 새로운 층을 만들 수 있다.\n",
        "\n",
        "따라서 위 모델은 두 개의 층을 가진 모델이며, 마지막 층은 결과를 출력하는 '출력층'이 된다.</br>이 때 나머지층은 모두 '은닉층'이 된다.\n",
        "\n",
        "그리고 각각의 층은 **Dense**라는 함수를 통해 구체적으로 그 구조가 결정이 된다.\n",
        "\n",
        "```\n",
        "Dense(30, input_dim=17, activation='relu')\n",
        "```\n",
        "Dense()함수를 통해 이 층에 몇 개의 노드를 만들 것인지를 숫자로 써준다.</br>이어서 입력 데이터를 몇 개 가져올 것인지 **input_dim**을 통해서 정해준다.\n",
        "</br>이제 은닉층의 각 노드는 17개의 입력 값에서 임의의 가중치를 가지고(편향값도 더해졌을 수도 있음) 각 노드로 전송되어 활성화 함수를 만난다.</br>이 때 어떤 활성화 함수를 사용할 것인지를 **activation** 부분에 정해준다.\n",
        "\n",
        "```\n",
        "Dense(1, activation='sigmoid')\n",
        "\n",
        "```\n",
        "마지막 층은 출력층으로 1개의 노드를 필요로 하며 시그모이드 함수를 사용하였다.\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100, batch_size = 10)\n",
        "```\n",
        "\n",
        "모델 컴파일 부분은 오차함수를 **평균 제곱 오차 함수 mean squared error**를 사용하며 최적화 방식은 **adam**으로 지정하였다.\n",
        "\n",
        "다음으로 **metrics()** 부분은 모델이 컴파일될 때 모델 수행 결과를 나타내게끔 설정하는 부분이다.\n",
        "\n",
        "척도(metrics)의 개념으로는 정확도/정밀도/재현율 등이 있으며 케라스 척도의 종류는 [다음](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)에서 볼 수 있다.\n"
      ],
      "metadata": {
        "id": "crP4NUqmUTe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 교차 엔트로피 Cross entropy\n",
        "\n",
        "교차 엔트로피는 분류 문제에서 자주 사용되며 수식은 다음과 같다.\n",
        "\n",
        "$$E = -\\sum_{k} t_{k}log(y_{k})$$\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 원-핫 인코딩\n",
        "\n",
        "y = [.1, .05, .6, .0, .05, .1, .0, .1, .0, .0]\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        ">>> 0.510825457099338\n",
        "\n",
        "y2 = [.1, .05, .1, .0, .05, .1, .0, .6, .0, .0]\n",
        "print(cross_entropy_error(np.array(y2), np.array(t)))\n",
        ">>> 2.302584092994546\n",
        "     \n",
        "```\n",
        "\n",
        "\n",
        "특별히 예측 값이 참과 거짓 둘 중 하나인 형식일 때는 **binary_crossentropy** (이항 교체 엔트로피)를 쓴다. 위의 예시가 좋은 예이다.\n",
        "\n",
        "손실함수의 계산에 대한 내용은 이전 [스터디](https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/1%EA%B6%8C_4%EC%9E%A5(1)_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%ED%95%99%EC%8A%B5.ipynb)에 코드 정리가 더 되어있다.\n",
        "\n",
        "위 코드에 적용하고 싶은 경우\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "이항 교차 엔트로피 적용\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "```\n",
        "아래와 같이 바꾸어주면 된다."
      ],
      "metadata": {
        "id": "GZZXs6qajawa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#실행\n",
        "model2.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "model2.fit(X, Y, epochs=100, batch_size = 10)"
      ],
      "metadata": {
        "id": "nBW2GcZumTLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de399d19-ecf7-4aae-8af9-51623ae77577"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 1s 2ms/step - loss: 2.7431 - accuracy: 0.6468\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.9907 - accuracy: 0.7234\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8511\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8489\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8468\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8489\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8511\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8489\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8511\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8340\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8234\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8468\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8511\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8319\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8447\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8404\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8447\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8489\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8489\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8511\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8298\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8489\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8489\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8298\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8489\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8426\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8511\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8468\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8511\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8383\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8511\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8404\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8511\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8404\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8383\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8511\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8553\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8489\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8404\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8511\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8404\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8489\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8511\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8255\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8489\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8468\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8489\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8489\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8596\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8447\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8468\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8426\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8532\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8532\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8532\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8511\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8532\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8553\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8511\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8447\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8404\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8553\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8362\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8489\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8511\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8426\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8532\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8532\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8298\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8511\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8511\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8574\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8574\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8468\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8553\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8383\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8447\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8426\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8553\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8511\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8404\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8553\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8489\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8404\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8596\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8468\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8574\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8426\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8468\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8426\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8447\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8447\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8277\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8255\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8426\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8574\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8489\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc157292b80>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "교재에서는 정확도가 약간 향상되는 것을 볼 수 있다지만 나는 그닥 차이점을 모르겠다.\n",
        "\n",
        "마지막 model.fit 부분이다.\n",
        "\n",
        "```\n",
        "model.fit(X, Y, epochs=100, batch_size=10)\n",
        "```\n",
        "epoch 이란 학습 프로세스가 모든 샘플에 대해 한 번 실행되는 것을 1 epoch 이라고 한다.</br>batch_size=10 은 전체 470개의 샘플을 10개씩 끊어서 집어넣으라는 뜻이 되며 이 크기가 너무 클 경우 학습 속도가 느려지고, 너무 작을 경우 실행 값의 편차가 생겨서 결과값이 불안정해진다."
      ],
      "metadata": {
        "id": "r7lhJVfQqbWG"
      }
    }
  ]
}