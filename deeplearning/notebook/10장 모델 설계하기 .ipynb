{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mSvnn-ZWd9ef",
        "UhcQBmxwO5Vm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirals88/DL_for_everyone/blob/main/deeplearning/notebook/10%EC%9E%A5%20%EB%AA%A8%EB%8D%B8%20%EC%84%A4%EA%B3%84%ED%95%98%EA%B8%B0%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'모두의 딥러닝' 책 스터디 내용을 jupyter notebook으로 정리하여 올립니다.\n",
        "\n",
        "Github 주소 : 'https://github.com/gilbutITbook/080228'\n",
        "\n",
        "**모두의 딥러닝**"
      ],
      "metadata": {
        "id": "WdeE-kzODzDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 장 모델 설계하기기\n",
        "\n",
        "01장에서 **폐암 수술 환자의 생존율 예측하기** 예제 코드를 잠시 보았다.\n",
        "\n",
        "먼저 해당 코드를 다시 보면 다음과 같다.\n"
      ],
      "metadata": {
        "id": "mSvnn-ZWd9ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 폐암 수술 환자의 생존율 예측하기 실습 / 예제 코드\n",
        "\n",
        "# 딥러닝 구동을 위한 케라스 함수 호출\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "#필요한 라이브러리 불러오기\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
        "\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "# 준비된 수술 환자 데이터 불러오기\n",
        "Data_set = np.loadtxt(\"https://raw.githubusercontent.com/tirals88/DL_for_everyone/main/deeplearning/dataset/ThoraricSurgery.csv\", delimiter=\",\")\n",
        "\n",
        "#환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
        "X = Data_set[:, 0:17]\n",
        "Y = Data_set[:, 17]\n",
        "\n",
        "#딥러닝 구조를 결정(모델 설정 / 실행)\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#실행\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100, batch_size = 10)"
      ],
      "metadata": {
        "id": "eKROL3263FGD",
        "outputId": "55a54bf6-3d39-4c74-fc65-42564188fca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 1s 2ms/step - loss: 0.7505 - accuracy: 0.2340\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.3872\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.8489\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1553256a0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 위 코드는 **model**이라는 함수를 선언하며 시작이 된다.\n",
        ">> **model.compile()** 부분은 위에서 정해진 모델을 컴퓨터가 알아들을 수 있게끔 컴파일 하는 부분이다.\n",
        ">>>**model.fit()**으로 시작하는 부분은 모델을 실제로 수행하는 부분이다.\n",
        "\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=17, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "```\n",
        "딥러닝이란 퍼센트론 위에 숨겨진 퍼셉트론 층을 차곡차곡 추가하는 형태임을 배웠다.\n",
        "\n",
        "이 층들이 케라스에서는 **Sequential()** 함수를 통해 쉽게 구현된다.\n",
        "\n",
        "위와 같이 Sequential() 함수를 선언한 후, add() 를 통해 새로운 층을 만들 수 있다.\n",
        "\n",
        "따라서 위 모델은 두 개의 층을 가진 모델이며, 마지막 층은 결과를 출력하는 '출력층'이 된다.</br>이 때 나머지층은 모두 '은닉층'이 된다.\n",
        "\n",
        "그리고 각각의 층은 **Dense**라는 함수를 통해 구체적으로 그 구조가 결정이 된다.\n",
        "\n",
        "```\n",
        "Dense(30, input_dim=17, activation='relu')\n",
        "```\n",
        "Dense()함수를 통해 이 층에 몇 개의 노드를 만들 것인지를 숫자로 써준다.</br>이어서 입력 데이터를 몇 개 가져올 것인지 **input_dim**을 통해서 정해준다.\n",
        "</br>이제 은닉층의 각 노드는 17개의 입력 값에서 임의의 가중치를 가지고(편향값도 더해졌을 수도 있음) 각 노드로 전송되어 활성화 함수를 만난다.</br>이 때 어떤 활성화 함수를 사용할 것인지를 **activation** 부분에 정해준다.\n",
        "\n",
        "```\n",
        "Dense(1, activation='sigmoid')\n",
        "\n",
        "```\n",
        "마지막 층은 출력층으로 1개의 노드를 필요로 하며 시그모이드 함수를 사용하였다.\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100, batch_size = 10)\n",
        "```\n",
        "\n",
        "모델 컴파일 부분은 오차함수를 **평균 제곱 오차 함수 mean squared error**를 사용하며 최적화 방식은 **adam**으로 지정하였다.\n",
        "\n",
        "다음으로 **metrics()** 부분은 모델이 컴파일될 때 모델 수행 결과를 나타내게끔 설정하는 부분이다.\n",
        "\n",
        "척도(metrics)의 개념으로는 정확도/정밀도/재현율 등이 있으며 케라스 척도의 종류는 [다음](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)에서 볼 수 있다.\n"
      ],
      "metadata": {
        "id": "crP4NUqmUTe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 교차 엔트로피 Cross entropy\n",
        "\n",
        "교차 엔트로피는 분류 문제에서 자주 사용되며 수식은 다음과 같다.\n",
        "\n",
        "$$E = -\\sum_{k} t_{k}log(y_{k})$$\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 원-핫 인코딩\n",
        "\n",
        "y = [.1, .05, .6, .0, .05, .1, .0, .1, .0, .0]\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        ">>> 0.510825457099338\n",
        "\n",
        "y2 = [.1, .05, .1, .0, .05, .1, .0, .6, .0, .0]\n",
        "print(cross_entropy_error(np.array(y2), np.array(t)))\n",
        ">>> 2.302584092994546\n",
        "     \n",
        "```\n",
        "\n",
        "\n",
        "특별히 예측 값이 참과 거짓 둘 중 하나인 형식일 때는 **binary_crossentropy** (이항 교체 엔트로피)를 쓴다. 위의 예시가 좋은 예이다.\n",
        "\n",
        "손실함수의 계산에 대한 내용은 이전 [스터디](https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/1%EA%B6%8C_4%EC%9E%A5(1)_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%ED%95%99%EC%8A%B5.ipynb)에 코드 정리가 더 되어있다.\n",
        "\n",
        "위 코드에 적용하고 싶은 경우\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])\n",
        "이항 교차 엔트로피 적용\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "```\n",
        "아래와 같이 바꾸어주면 된다."
      ],
      "metadata": {
        "id": "GZZXs6qajawa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#실행\n",
        "model2.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "model2.fit(X, Y, epochs=100, batch_size = 10)"
      ],
      "metadata": {
        "id": "nBW2GcZumTLG",
        "outputId": "975cdc32-3eab-4c52-face-0a436012c33e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 1s 1ms/step - loss: 0.5843 - accuracy: 0.8021\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.8319\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8298\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.8277\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8383\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8426\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8468\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8404\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8468\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8426\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8426\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8426\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8255\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8149\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8191\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8404\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8255\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8383\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8340\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8468\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8468\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8426\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8489\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8340\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8362\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8468\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8277\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8468\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8404\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8426\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8404\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8511\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8426\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8468\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8447\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8468\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8383\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8532\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8468\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8489\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8511\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8255\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8489\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8383\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8511\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8553\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8255\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8468\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8426\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8404\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8489\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8468\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8447\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8426\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8489\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8532\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8511\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8511\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8511\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8617\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8638\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8447\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8447\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8489\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8574\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8383\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8489\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8574\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8404\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8532\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8532\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8319\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8532\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8574\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8574\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8532\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8447\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8532\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8404\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8553\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8489\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8553\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8638\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8319\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8574\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8511\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8426\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8617\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8447\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8660\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8404\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8468\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8553\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8447\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8532\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8383\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8277\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8447\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8638\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8553\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1576c8a90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "교재에서는 정확도가 약간 향상되는 것을 볼 수 있다지만 나는 그닥 차이점을 모르겠다.\n",
        "\n",
        "마지막 model.fit 부분이다.\n",
        "\n",
        "```\n",
        "model.fit(X, Y, epochs=100, batch_size=10)\n",
        "```\n",
        "epoch 이란 학습 프로세스가 모든 샘플에 대해 한 번 실행되는 것을 1 epoch 이라고 한다.</br>batch_size=10 은 전체 470개의 샘플을 10개씩 끊어서 집어넣으라는 뜻이 되며 이 크기가 너무 클 경우 학습 속도가 느려지고, 너무 작을 경우 실행 값의 편차가 생겨서 결과값이 불안정해진다."
      ],
      "metadata": {
        "id": "r7lhJVfQqbWG"
      }
    }
  ]
}